{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c-eEbm_6Guy"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irIDXlHb3MdY"
      },
      "outputs": [],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PK-cdRe-2VQt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "#from sklearn.pipeline import Pipeline\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "sns.set_theme(context='notebook', palette='muted', style='darkgrid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VVjREz83Few"
      },
      "outputs": [],
      "source": [
        "main_df = pd.read_csv(\"/content/alzheimers_disease_data.csv\")\n",
        "main_df.head().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "frz7hkhK3OZA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCNPfBjr3Ta4"
      },
      "outputs": [],
      "source": [
        "main_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjF3Fj1y3ky_"
      },
      "outputs": [],
      "source": [
        "main_df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xidaaldT3qT3"
      },
      "outputs": [],
      "source": [
        "sum(main_df.duplicated())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1T3rsYD4s3Y"
      },
      "outputs": [],
      "source": [
        "len(main_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlOCaA0g36xf"
      },
      "outputs": [],
      "source": [
        "main_df.drop(['PatientID', 'DoctorInCharge'], axis=1, inplace=True)\n",
        "len(main_df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32F6qPgL6e7Y"
      },
      "source": [
        "<div style=\"padding: 20px; border-radius: 10px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border: 2px solid #888888;\">\n",
        "    <h1 style=\"font-size: 24px; font-family: 'Arial'; color: #c77220\"><b>Initial Data Exploration Summary</b></h1>\n",
        "    <ul style=\"font-size: 20px; font-family: 'Arial'; line-height: 1.5em;\">\n",
        "        <li>The dataset contains a total of <strong>2,149 observations</strong>.</li>\n",
        "        <li>All values in the dataset are <strong>non-null</strong> and <strong>numerical</strong>.</li>\n",
        "        <li>There are <strong>no duplicate</strong> records.</li>\n",
        "        <li>After removing the `DoctorInCharge` and `PatientID` columns, the dataset consists of <strong>33 features</strong>.</li>\n",
        "    </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ_J_a8K7O6q"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pw_snojN7RxA"
      },
      "outputs": [],
      "source": [
        "# Identify numerical columns: columns with more than 10 unique values are considered numerical\n",
        "numerical_columns = [col for col in main_df.columns if main_df[col].nunique() > 10]\n",
        "\n",
        "# Identify categorical columns: columns that are not numerical and not 'Diagnosis'\n",
        "categorical_columns = main_df.columns.difference(numerical_columns).difference(['Diagnosis']).to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhV84JoQ4XEv"
      },
      "outputs": [],
      "source": [
        "# Custom labels for the categorical columns\n",
        "custom_labels = {\n",
        "    'Gender': ['Male', 'Female'],\n",
        "    'Ethnicity': ['Caucasian', 'African American', 'Asian', 'Other'],\n",
        "    'EducationLevel': ['None', 'High School', 'Bachelor\\'s', 'Higher'],\n",
        "    'Smoking': ['No', 'Yes'],\n",
        "    'FamilyHistoryAlzheimers': ['No', 'Yes'],\n",
        "    'CardiovascularDisease': ['No', 'Yes'],\n",
        "    'Diabetes': ['No', 'Yes'],\n",
        "    'Depression': ['No', 'Yes'],\n",
        "    'HeadInjury': ['No', 'Yes'],\n",
        "    'Hypertension': ['No', 'Yes'],\n",
        "    'MemoryComplaints': ['No', 'Yes'],\n",
        "    'BehavioralProblems': ['No', 'Yes'],\n",
        "    'Confusion': ['No', 'Yes'],\n",
        "    'Disorientation': ['No', 'Yes'],\n",
        "    'PersonalityChanges': ['No', 'Yes'],\n",
        "    'DifficultyCompletingTasks': ['No', 'Yes'],\n",
        "    'Forgetfulness': ['No', 'Yes']\n",
        "}\n",
        "\n",
        "# Plot countplots for each categorical column\n",
        "for column in categorical_columns:\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.countplot(data=main_df, x=column)\n",
        "    plt.title(f'Countplot of {column}')\n",
        "\n",
        "    # Directly set custom labels\n",
        "    labels = custom_labels[column]\n",
        "    ticks = range(len(labels))\n",
        "    plt.xticks(ticks=ticks, labels=labels)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHhGx01f8ojA"
      },
      "source": [
        "<div style=\"padding: 20px; border-radius: 10px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border: 2px solid #888888;\">\n",
        "    <h1 style=\"font-size: 24px; font-family: 'Arial'; color: #c77220\"><b>Observations from Visualization of Categorical Features</b></h1>\n",
        "    <ul style=\"font-size: 20px; font-family: 'Arial'; line-height: 1.5em;\">\n",
        "        <li>Overall, the dataset predominantly consists of individuals <strong>without disease or health problems</strong>.</li>\n",
        "        <li><strong>Caucasian</strong>. The most represented demographic is</li>\n",
        "        <li><strong>High school</strong> graduates constitute the largest educational group, closely followed by individuals with a <strong>bachelor's</strong> degree.</li>\n",
        "        <li>Notably, both <strong>females</strong> and <strong>males</strong> are equally represented across the dataset.</li>\n",
        "    </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "279HiEaJ8o0_"
      },
      "outputs": [],
      "source": [
        "# Plot histogram for each numerical column\n",
        "for column in numerical_columns:\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.histplot(data=main_df, x=column, kde=True, bins=20)\n",
        "    plt.title(f'Distribution of {column}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkFNF7GJ87n_"
      },
      "source": [
        "<div style=\"padding: 20px; border-radius: 10px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border: 2px solid #888888;\">\n",
        "    <h1 style=\"font-size: 24px; font-family: 'Arial'; color: #c77220\"><b>Observations from Visualization of Numerical Features</b></h1>\n",
        "    <ul style=\"font-size: 20px; font-family: 'Arial'; line-height: 1.5em;\">\n",
        "        <li>Most of the columns show a <strong>fairly uniform</strong> distribution. </li>\n",
        "        <li>The `MMSE` (Mini-Mental State Examination) scores appear to follow a <strong>bimodal</strong> distribution, indicating two distinct groups within the data.</li>\n",
        "    </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoF44FYo87XY"
      },
      "outputs": [],
      "source": [
        "# Create a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(main_df.corr(), dtype=bool))\n",
        "\n",
        "# Plot heatmap of the correlation matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(main_df.corr(),cmap=\"coolwarm\", cbar_kws={\"shrink\": .5}, mask=mask)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H05EAZnr-xfg"
      },
      "source": [
        "The heatmap reveals that the features do not have any strong correlations among themselves. However, there are five columns that show a correlation **with the target variable**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Uu2MF-5-x1_"
      },
      "outputs": [],
      "source": [
        "# Compute Pearson correlation coefficients\n",
        "correlations = main_df.corr(numeric_only=True)['Diagnosis'][:-1].sort_values()\n",
        "\n",
        "# Set the size of the figure\n",
        "plt.figure(figsize=(20, 7))\n",
        "\n",
        "# Create a bar plot of the Pearson correlation coefficients\n",
        "ax = correlations.plot(kind='bar', width=0.7)\n",
        "\n",
        "# Set the y-axis limits and labels\n",
        "ax.set(ylim=[-1, 1], ylabel='Pearson Correlation', xlabel='Features',\n",
        "       title='Pearson Correlation with Diagnosis')\n",
        "\n",
        "# Rotate x-axis labels for better readability\n",
        "ax.set_xticklabels(correlations.index, rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT9e-9DQ-6Zg"
      },
      "source": [
        "<div style=\"padding: 20px; border-radius: 10px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border: 2px solid #888888;\">\n",
        "    <h1 style=\"font-size: 24px; font-family: 'Arial'; color: #c77220\"><b>Observations from Exploring Correlations</b></h1>\n",
        "    <ul style=\"font-size: 20px; font-family: 'Arial'; line-height: 1.5em;\">\n",
        "        <li>As observed, there are five columns correlated with the target variable.</li>\n",
        "        <li>Three numerical features—`Functional Assessment`, `ADL` (Activities of Daily Living), and `MMSE` (Mini-Mental State Examination)—are <strong>negatively</strong> correlated with the `diagnosis of Alzheimer's disease`, with correlation coefficients of -0.36, -0.33, and -0.24 respectively. This indicates that lower scores in these assessments are associated with a higher likelihood of an Alzheimer's diagnosis.</li>\n",
        "        <li>Additionally, two categorical variables—`Behavioral Problems` and `Memory Complaints`—are <strong>positively</strong> correlated with the `diagnosis`, with correlation coefficients of 0.22 and 0.30 respectively. This means the presence of these issues is associated with a higher likelihood of an Alzheimer's diagnosis, highlighting their significance in the diagnostic process.</li>\n",
        "    </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FckptIHt-1fH"
      },
      "outputs": [],
      "source": [
        "# Define the Response categories and count occurences\n",
        "categories = [0, 1]\n",
        "counts = main_df.Diagnosis.value_counts().tolist()\n",
        "\n",
        "# Choose a color palette from Seaborn for the pie chart\n",
        "colors = sns.color_palette(\"muted\")\n",
        "\n",
        "# Plot the pie chart with the counts of each response category\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(counts, labels=categories, autopct='%1.1f%%', startangle=140, colors=colors)\n",
        "plt.title('Diagnosis Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8XKudlxgNaX"
      },
      "outputs": [],
      "source": [
        "main_df['Diagnosis'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhXbfoxP_d4I"
      },
      "source": [
        "<div style=\"padding: 20px; border-radius: 10px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border: 2px solid #888888;\">\n",
        "    <h1 style=\"font-size: 24px; font-family: 'Arial'; color: #c77220\"><b>Observation from the Target Distribution</b></h1>\n",
        "    <ul style=\"font-size: 20px; font-family: 'Arial'; line-height: 1.5em;\">\n",
        "        <li>The target variable is <strong>moderately imbalanced</strong>, with 65% of instances being 0 and 35% being 1.</li>\n",
        "    </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQRZOmf__kw4"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4sbu3I88Zox"
      },
      "outputs": [],
      "source": [
        "for i in main_df['Gender']:\n",
        "  if i == 0:\n",
        "    main_df['Gender'].replace(0, 'Male', inplace=True)\n",
        "  else:\n",
        "    main_df['Gender'].replace(1, 'Female', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCqpqt-S96tw"
      },
      "outputs": [],
      "source": [
        "for i in main_df['Ethnicity']:\n",
        "  if i == 0:\n",
        "    main_df['Ethnicity'].replace(0, 'Caucasian', inplace=True)\n",
        "  elif i == 1:\n",
        "    main_df['Ethnicity'].replace(1, 'African American', inplace=True)\n",
        "  elif i == 2:\n",
        "    main_df['Ethnicity'].replace(2, 'Asian', inplace=True)\n",
        "  else:\n",
        "    main_df['Ethnicity'].replace(3, 'Other', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF3klXKUFDsG"
      },
      "outputs": [],
      "source": [
        "for i in main_df['EducationLevel']:\n",
        "  if i == 0:\n",
        "    main_df['EducationLevel'].replace(0, 'None', inplace=True)\n",
        "  elif i == 1:\n",
        "    main_df['EducationLevel'].replace(1, 'High School', inplace=True)\n",
        "  elif i == 2:\n",
        "    main_df['EducationLevel'].replace(2, 'Bachelor\\'s', inplace=True)\n",
        "  else:\n",
        "    main_df['EducationLevel'].replace(3, 'Higher', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5kmI6cB-PKA"
      },
      "outputs": [],
      "source": [
        "main_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXqySQDh-UMI"
      },
      "outputs": [],
      "source": [
        "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False).set_output(transform=\"pandas\")\n",
        "ohe_transform = ohe.fit_transform(main_df[['Gender']])\n",
        "main_df = pd.concat([main_df, ohe_transform], axis=1).drop(columns=['Gender'])\n",
        "main_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26RDF4XWAM6w"
      },
      "outputs": [],
      "source": [
        "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False).set_output(transform=\"pandas\")\n",
        "ohe_transform = ohe.fit_transform(main_df[['Ethnicity']])\n",
        "main_df = pd.concat([main_df, ohe_transform], axis=1).drop(columns=['Ethnicity'])\n",
        "main_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLRTlCDkFbeO"
      },
      "outputs": [],
      "source": [
        "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False).set_output(transform=\"pandas\")\n",
        "ohe_transform = ohe.fit_transform(main_df[['EducationLevel']])\n",
        "main_df = pd.concat([main_df, ohe_transform], axis=1).drop(columns=['EducationLevel'])\n",
        "main_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJZ6MUAW_bOg"
      },
      "outputs": [],
      "source": [
        "#unique values in each column\n",
        "for column in main_df.columns:\n",
        "    unique_values = main_df[column].unique()\n",
        "    print(f\"Unique values in column '{column}':\")\n",
        "    print(unique_values)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUpwl2wG_bLg"
      },
      "outputs": [],
      "source": [
        "#split data into features and target\n",
        "X = main_df.drop(columns = ['Diagnosis'])\n",
        "y = main_df['Diagnosis']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeeFwSSS_bJL"
      },
      "outputs": [],
      "source": [
        "#split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 4646, shuffle = True, stratify = y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KVDotwrJTyV"
      },
      "source": [
        "# Scaling Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9z9ntw0QJTi8"
      },
      "outputs": [],
      "source": [
        "columns_to_scale = continuous_features = [\"Age\", \"BMI\", \"AlcoholConsumption\", \"PhysicalActivity\", \"DietQuality\", \"SleepQuality\", \"SystolicBP\", \"DiastolicBP\", \"CholesterolTotal\", \"CholesterolLDL\", \"CholesterolHDL\", \"CholesterolTriglycerides\", \"MMSE\", \"FunctionalAssessment\", \"ADL\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Sl7IdF1HXxl"
      },
      "source": [
        "# Standard Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0FSirf4_bGq"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_standardized = X_train.copy()\n",
        "X_train_standardized = scaler.fit_transform(X_train[columns_to_scale])\n",
        "\n",
        "X_test_standardized = X_test.copy()\n",
        "X_test_standardized = scaler.transform(X_test[columns_to_scale])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QvzsdJ4LF-c"
      },
      "source": [
        "## Resampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVSyjLhhLFST"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(sampling_strategy='minority')\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_standardized, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIDMuGfACsV2"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(sampling_strategy='minority')\n",
        "X_train_resampled2, y_train_resampled2 = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U50e1CaKL-hz"
      },
      "outputs": [],
      "source": [
        "y_train_resampled.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeAoItsRDiUW"
      },
      "outputs": [],
      "source": [
        "y_train_resampled2.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdMpS04RJ1U0"
      },
      "source": [
        "## Training-01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjsOwoP-QOQS"
      },
      "outputs": [],
      "source": [
        "best_estimators = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Dbvoki3_bD4"
      },
      "outputs": [],
      "source": [
        "#define hyperparameter grids for each model\n",
        "param_grids = {\n",
        "    'K-Nearest Neighbors': {'n_neighbors': [3, 5, 7]},\n",
        "    'Logistic Regression': {'C': [0.1, 1, 10]},\n",
        "    'Support Vector Machine': {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 'scale', 'auto']}\n",
        "}\n",
        "\n",
        "#instantiate classification models with default parameters\n",
        "models = {\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Support Vector Machine': SVC()\n",
        "}\n",
        "\n",
        "#fit models using GridSearchCV for hyperparameter tuning\n",
        "for name, model in models.items():\n",
        "    grid_search = GridSearchCV(model, param_grids[name], cv = 5, scoring = 'f1')\n",
        "    grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test_standardized)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    best_estimators1 = {}\n",
        "    best_estimators1[name] = grid_search.best_estimator_\n",
        "    best_estimators.update(best_estimators1)\n",
        "    print(f'{name} Classification Report:\\n{report}\\nBest Parameters: {grid_search.best_params_}\\n')\n",
        "\n",
        "    roc_auc_score = roc_auc_score(y_test, y_pred)\n",
        "    print(f'ROC AUC Score: {roc_auc_score}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG-AVx8u_a4Y"
      },
      "outputs": [],
      "source": [
        "#define hyperparameter grids for each model\n",
        "param_grids = {\n",
        "    'Decision Tree': {'max_depth': [3, 5, 7, 12, None]},\n",
        "    'Random Forest': {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7, 12, None]},\n",
        "    'XGBoost': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1], 'max_depth': [3, 5, 7]},\n",
        "    'GradientBoostingClassifier': {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1, 0.5]},\n",
        "    'CatBoost': {'iterations': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1]}\n",
        "}\n",
        "\n",
        "#instantiate classification models with default parameters\n",
        "models = {\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'XGBoost': XGBClassifier(),\n",
        "    'GradientBoostingClassifier': GradientBoostingClassifier(random_state=4646),\n",
        "    'CatBoost': CatBoostClassifier(verbose=0)\n",
        "}\n",
        "\n",
        "#fit models using GridSearchCV for hyperparameter tuning\n",
        "for name, model in models.items():\n",
        "    grid_search = GridSearchCV(model, param_grids[name], cv = 5, scoring = 'f1')\n",
        "    grid_search.fit(X_train_resampled2, y_train_resampled2)\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    best_estimators1 = {}\n",
        "    best_estimators1[name] = grid_search.best_estimator_\n",
        "    best_estimators.update(best_estimators1)\n",
        "    print(f'{name} Classification Report:\\n{report}\\nBest Parameters: {grid_search.best_params_}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XCb944B8Tkw"
      },
      "source": [
        "## Ensemble Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-_u0Ot5MJoD"
      },
      "source": [
        "### Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2jGph0tKgtE"
      },
      "outputs": [],
      "source": [
        "catBoost_pipeline = Pipeline([\n",
        "    ('smote', SMOTE(sampling_strategy='minority')),\n",
        "    ('CatBoost', best_estimators['CatBoost'])\n",
        "])\n",
        "\n",
        "xgboost_pipeline = Pipeline([\n",
        "    ('smote', SMOTE(sampling_strategy='minority')),\n",
        "    ('XGBoost', best_estimators['XGBoost'])\n",
        "])\n",
        "\n",
        "gradientBoosting_pipeline = Pipeline([\n",
        "    ('smote', SMOTE(sampling_strategy='minority')),\n",
        "    ('GradientBoostingClassifier', best_estimators['GradientBoostingClassifier'])\n",
        "])\n",
        "\n",
        "svm_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('smote', SMOTE(sampling_strategy='minority')),\n",
        "    ('SVM', best_estimators['Support Vector Machine'])\n",
        "])\n",
        "\n",
        "knn_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('smote', SMOTE(sampling_strategy='minority')),\n",
        "    ('KNN', best_estimators['K-Nearest Neighbors'])\n",
        "])\n",
        "\n",
        "logistic_regression_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('smote', SMOTE(sampling_strategy='minority')),\n",
        "    ('LogisticRegression', best_estimators['Logistic Regression'])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hq9fa-zi_ayq"
      },
      "outputs": [],
      "source": [
        "estimators = [\n",
        "    ('CatBoost', catBoost_pipeline),\n",
        "    ('XGBoost', xgboost_pipeline),\n",
        "    ('GradientBoostingClassifier', gradientBoosting_pipeline),\n",
        "    ('Support Vector Machine', svm_pipeline)\n",
        "]\n",
        "\n",
        "# Define the final estimator (meta-model)\n",
        "final_estimator = GradientBoostingClassifier()\n",
        "\n",
        "# Create the stacking classifier\n",
        "stacking_model = StackingClassifier(estimators=estimators, final_estimator=final_estimator, cv=5)\n",
        "\n",
        "# Fit the stacking classifier on the training data\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = stacking_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(f'Stacking Classifier Classification Report:\\n{report}\\n')\n",
        "\n",
        "# Evaluate stacking model\n",
        "y_pred_stacking = stacking_model.predict(X_test)\n",
        "if hasattr(stacking_model, \"predict_proba\"):\n",
        "    y_pred_proba_stacking = stacking_model.predict_proba(X_test)[:, 1]\n",
        "else:\n",
        "    y_pred_proba_stacking = None\n",
        "\n",
        "stack_roc_auc_score = roc_auc_score(y_test, y_pred_proba_stacking) if y_pred_proba_stacking is not None else 'N/A'\n",
        "print(f'Stacking Classifier ROC AUC Score: {stack_roc_auc_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hfoi6dojt_En"
      },
      "outputs": [],
      "source": [
        "estimators = [\n",
        "    ('CatBoost', catBoost_pipeline),\n",
        "    ('XGBoost', xgboost_pipeline)\n",
        "]\n",
        "\n",
        "# Define the final estimator (meta-model)\n",
        "final_estimator = LogisticRegression()\n",
        "\n",
        "# Create the stacking classifier\n",
        "stacking_model = StackingClassifier(estimators=estimators, final_estimator=final_estimator, cv=5)\n",
        "\n",
        "# Fit the stacking classifier on the training data\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = stacking_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(f'Stacking Classifier Classification Report:\\n{report}\\n')\n",
        "\n",
        "# Evaluate stacking model\n",
        "y_pred_stacking = stacking_model.predict(X_test)\n",
        "if hasattr(stacking_model, \"predict_proba\"):\n",
        "    y_pred_proba_stacking = stacking_model.predict_proba(X_test)[:, 1]\n",
        "else:\n",
        "    y_pred_proba_stacking = None\n",
        "\n",
        "stack_roc_auc_score = roc_auc_score(y_test, y_pred_proba_stacking) if y_pred_proba_stacking is not None else 'N/A'\n",
        "print(f'Stacking Classifier ROC AUC Score: {stack_roc_auc_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlx0EaP5zFuF"
      },
      "outputs": [],
      "source": [
        "estimators = [\n",
        "    ('CatBoost', catBoost_pipeline),\n",
        "    ('XGBoost', xgboost_pipeline)\n",
        "]\n",
        "\n",
        "# Define the final estimator (meta-model)\n",
        "final_estimator = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Create the stacking classifier\n",
        "stacking_model = StackingClassifier(estimators=estimators, final_estimator=final_estimator, cv=5)\n",
        "\n",
        "# Fit the stacking classifier on the training data\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = stacking_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(f'Stacking Classifier Classification Report:\\n{report}\\n')\n",
        "\n",
        "# Evaluate stacking model\n",
        "y_pred_stacking = stacking_model.predict(X_test)\n",
        "if hasattr(stacking_model, \"predict_proba\"):\n",
        "    y_pred_proba_stacking = stacking_model.predict_proba(X_test)[:, 1]\n",
        "else:\n",
        "    y_pred_proba_stacking = None\n",
        "\n",
        "stack_roc_auc_score = roc_auc_score(y_test, y_pred_proba_stacking) if y_pred_proba_stacking is not None else 'N/A'\n",
        "print(f'Stacking Classifier ROC AUC Score: {stack_roc_auc_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6Y3Yr0I0I8h"
      },
      "outputs": [],
      "source": [
        "estimators = [\n",
        "    ('CatBoost', catBoost_pipeline),\n",
        "    ('XGBoost', xgboost_pipeline)\n",
        "]\n",
        "\n",
        "# Define the final estimator (meta-model)\n",
        "final_estimator = SVC(C=1.0, gamma='auto')\n",
        "\n",
        "# Create the stacking classifier\n",
        "stacking_model = StackingClassifier(estimators=estimators, final_estimator=final_estimator, cv=5)\n",
        "\n",
        "# Fit the stacking classifier on the training data\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = stacking_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(f'Stacking Classifier Classification Report:\\n{report}\\n')\n",
        "\n",
        "# Evaluate stacking model\n",
        "y_pred_stacking = stacking_model.predict(X_test)\n",
        "if hasattr(stacking_model, \"predict_proba\"):\n",
        "    y_pred_proba_stacking = stacking_model.predict_proba(X_test)[:, 1]\n",
        "else:\n",
        "    y_pred_proba_stacking = None\n",
        "\n",
        "stack_roc_auc_score = roc_auc_score(y_test, y_pred_proba_stacking) if y_pred_proba_stacking is not None else 'N/A'\n",
        "print(f'Stacking Classifier ROC AUC Score: {stack_roc_auc_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mcj7y0Cc1K0W"
      },
      "outputs": [],
      "source": [
        "estimators = [\n",
        "    ('CatBoost', catBoost_pipeline),\n",
        "    ('XGBoost', xgboost_pipeline)\n",
        "]\n",
        "\n",
        "# Define the final estimator (meta-model)\n",
        "final_estimator = LogisticRegression(C=0.1)\n",
        "\n",
        "# Create the stacking classifier\n",
        "stacking_model = StackingClassifier(estimators=estimators, final_estimator=final_estimator, cv=5)\n",
        "\n",
        "# Fit the stacking classifier on the training data\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = stacking_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(f'Stacking Classifier Classification Report:\\n{report}\\n')\n",
        "\n",
        "# Evaluate stacking model\n",
        "y_pred_stacking = stacking_model.predict(X_test)\n",
        "if hasattr(stacking_model, \"predict_proba\"):\n",
        "    y_pred_proba_stacking = stacking_model.predict_proba(X_test)[:, 1]\n",
        "else:\n",
        "    y_pred_proba_stacking = None\n",
        "\n",
        "stack_roc_auc_score = roc_auc_score(y_test, y_pred_proba_stacking) if y_pred_proba_stacking is not None else 'N/A'\n",
        "print(f'Stacking Classifier ROC AUC Score: {stack_roc_auc_score}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtSIOtfVfq-g"
      },
      "source": [
        "## Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUYnZOorpbwS"
      },
      "outputs": [],
      "source": [
        "# The path to save the model\n",
        "model_path = '/content/Stack_std_LR_model3.joblib'\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(stacking_model, model_path)\n",
        "\n",
        "print(f\"Model saved successfully at: {model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g926jm3bfvX5"
      },
      "source": [
        "## Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Boq915V5fvJA"
      },
      "outputs": [],
      "source": [
        "model_path = '/content/stack_model2.joblib'\n",
        "loaded_model = joblib.load(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPIdvgNg50UQ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=loaded_model.classes_, yticklabels=loaded_model.classes_)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xviF2Gv16AmA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=loaded_model.classes_, yticklabels=loaded_model.classes_)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vN0WjCDp6LFv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=loaded_model.classes_, yticklabels=loaded_model.classes_)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTSJe3f_hHpA"
      },
      "source": [
        "## Test Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXeMYw_cgan3"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(f'Stacking Classifier Classification Report:\\n{report}\\n')\n",
        "\n",
        "# Evaluate stacking model\n",
        "y_pred_stacking = loaded_model.predict(X_test)\n",
        "if hasattr(loaded_model, \"predict_proba\"):\n",
        "    y_pred_proba_stacking = loaded_model.predict_proba(X_test)[:, 1]\n",
        "else:\n",
        "    y_pred_proba_stacking = None\n",
        "\n",
        "stack_roc_auc_score = roc_auc_score(y_test, y_pred_proba_stacking) if y_pred_proba_stacking is not None else 'N/A'\n",
        "print(f'Stacking Classifier ROC AUC Score: {stack_roc_auc_score}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aPyx2dO6hi3"
      },
      "source": [
        "# SHAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovreUXB6A9QG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import shap\n",
        "\n",
        "# Configure base estimators with probability predictions\n",
        "estimators = [\n",
        "    ('CatBoost', CatBoostClassifier(iterations=200, learning_rate=0.1, verbose=False)),\n",
        "    ('XGBoost', XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=3))\n",
        "]\n",
        "\n",
        "# Define the final estimator (meta-model)\n",
        "final_estimator = LogisticRegression(C=0.1)\n",
        "\n",
        "# Create the stacking classifier with predict_proba method\n",
        "stacking_model = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=final_estimator,\n",
        "    cv=5,\n",
        "    stack_method='predict_proba'  # Use probability predictions for stacking\n",
        ")\n",
        "\n",
        "# Fit the stacking classifier on the training data\n",
        "stacking_model.fit(X_train_resampled2, y_train_resampled2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnd75gSVBW6l"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = stacking_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(f'Stacking Classifier Classification Report:\\n{report}\\n')\n",
        "\n",
        "# Evaluate stacking model\n",
        "y_pred_stacking = stacking_model.predict(X_test)\n",
        "if hasattr(stacking_model, \"predict_proba\"):\n",
        "    y_pred_proba_stacking = stacking_model.predict_proba(X_test)[:, 1]\n",
        "else:\n",
        "    y_pred_proba_stacking = None\n",
        "\n",
        "stack_roc_auc_score = roc_auc_score(y_test, y_pred_proba_stacking) if y_pred_proba_stacking is not None else 'N/A'\n",
        "print(f'Stacking Classifier ROC AUC Score: {stack_roc_auc_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcNEXbk5GoBk"
      },
      "outputs": [],
      "source": [
        "X_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Vue9H1-6jaQ"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "shap.initjs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VX6TDkMERtH"
      },
      "outputs": [],
      "source": [
        "# Function to get predictions from the stacking model\n",
        "def predict_proba_wrapper(X):\n",
        "    # Ensure the input is in the right format\n",
        "    if isinstance(X, np.ndarray):\n",
        "        X = pd.DataFrame(X, columns=X_test.columns)\n",
        "    return stacking_model.predict_proba(X)[:, 1]  # Return only positive class probabilities\n",
        "\n",
        "# Create a background dataset for SHAP\n",
        "n_background = 100  # Number of background samples\n",
        "background_data = shap.sample(X_train_resampled2, n_background)\n",
        "\n",
        "# Initialize KernelExplainer with the wrapper function\n",
        "explainer = shap.KernelExplainer(predict_proba_wrapper, background_data)\n",
        "\n",
        "# Calculate SHAP values for a small test sample\n",
        "n_samples = 10  # Number of test samples to explain\n",
        "test_sample = X_test.iloc[:n_samples]\n",
        "shap_values = explainer.shap_values(test_sample)\n",
        "\n",
        "# Create summary plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "shap.summary_plot(shap_values, test_sample, feature_names=X_test.columns)\n",
        "plt.title(\"SHAP Summary Plot for Stacking Model\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create feature importance bar plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "shap.summary_plot(shap_values, test_sample, feature_names=X_test.columns, plot_type=\"bar\")\n",
        "plt.title(\"Feature Importance Based on SHAP Values\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate and display feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_test.columns,\n",
        "    'Importance': np.abs(shap_values).mean(0)\n",
        "})\n",
        "feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(feature_importance.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpYqrUaNP6H-"
      },
      "source": [
        "# ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HG5QsPUP5Yl"
      },
      "outputs": [],
      "source": [
        "#split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 4646, shuffle = True, stratify = y)\n",
        "\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size = 0.3, random_state = 4646, shuffle = True, stratify = y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKGPWmJl2RaS"
      },
      "source": [
        "## Standard Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5viC474QCIN"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_standardized = X_train.copy()\n",
        "X_train_standardized = scaler.fit_transform(X_train[columns_to_scale])\n",
        "\n",
        "X_test_standardized = X_test.copy()\n",
        "X_test_standardized = scaler.transform(X_test[columns_to_scale])\n",
        "\n",
        "X_valid_standardized = X_valid.copy()\n",
        "X_valid_standardized = scaler.transform(X_valid[columns_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTQpjl3QQQr2"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(sampling_strategy='minority')\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_standardized, y_train)\n",
        "y_train_resampled.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVW2VYMhQccF"
      },
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "  ax1.plot(history.history['loss'], label='loss')\n",
        "  ax1.plot(history.history['val_loss'], label='val_loss')\n",
        "  ax1.set_xlabel('Epoch')\n",
        "  ax1.set_ylabel('Binary crossentropy')\n",
        "  ax1.grid(True)\n",
        "\n",
        "  ax2.plot(history.history['accuracy'], label='accuracy')\n",
        "  ax2.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "  ax2.set_xlabel('Epoch')\n",
        "  ax2.set_ylabel('Accuracy')\n",
        "  ax2.grid(True)\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7AbjGKmQhC8"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, y_train, num_nodes, dropout_prob, lr, batch_size, epochs):\n",
        "  nn_model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(num_nodes, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "      tf.keras.layers.Dropout(dropout_prob),\n",
        "      tf.keras.layers.Dense(num_nodes, activation='relu'),\n",
        "      tf.keras.layers.Dropout(dropout_prob),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  nn_model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  history = nn_model.fit(\n",
        "    X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_valid_standardized, y_valid), verbose=0\n",
        "  )\n",
        "\n",
        "  return nn_model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoeqqD-oQkml"
      },
      "outputs": [],
      "source": [
        "least_val_loss = float('inf')\n",
        "least_loss_model = None\n",
        "epochs=100\n",
        "for num_nodes in [52, 78, 32]:\n",
        "  for dropout_prob in[0, 0.2]:\n",
        "    for lr in [0.01, 0.005, 0.001]:\n",
        "      for batch_size in [32, 64, 128]:\n",
        "        print(f\"{num_nodes} nodes, dropout {dropout_prob}, lr {lr}, batch size {batch_size}\")\n",
        "        model, history = train_model(X_train_resampled, y_train_resampled, num_nodes, dropout_prob, lr, batch_size, epochs)\n",
        "        plot_history(history)\n",
        "        val_loss = model.evaluate(X_valid_standardized, y_valid)[0]\n",
        "        if val_loss < least_val_loss:\n",
        "          least_val_loss = val_loss\n",
        "          least_loss_model = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5yfC5sdQoUt"
      },
      "outputs": [],
      "source": [
        "y_pred = least_loss_model.predict(X_test_standardized)\n",
        "y_pred = (y_pred > 0.5).astype(int).reshape(-1,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiAqUl24Qo_9"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6yg5IOOe3hC"
      },
      "source": [
        "## Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frIhIGHh4WrQ"
      },
      "outputs": [],
      "source": [
        "path = '/content/ann_standardized.keras'\n",
        "least_loss_model.save(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arkogpbAfXIB"
      },
      "source": [
        "## Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_6C6VXWfYrQ"
      },
      "outputs": [],
      "source": [
        "loaded_model = tf.keras.models.load_model(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYB1lWfUbSKe"
      },
      "source": [
        "# Min-Max Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jX0T7Alatvv"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train_normalized = X_train.copy()\n",
        "X_train_normalized = scaler.fit_transform(X_train[columns_to_scale])\n",
        "\n",
        "X_test_normalized = X_test.copy()\n",
        "X_test_normalized = scaler.transform(X_test[columns_to_scale])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxRI4Hombrc-"
      },
      "source": [
        "## Resampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_HlTRrobo3G"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(sampling_strategy='minority')\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_normalized, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wsN5vEgbrCF"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(sampling_strategy='minority')\n",
        "X_train_resampled2, y_train_resampled2 = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5G-KcJ2bzpe"
      },
      "source": [
        "## Training-01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5inTY9o7b2Gs"
      },
      "outputs": [],
      "source": [
        "best_estimators2 = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nkphvgr0b8pG"
      },
      "outputs": [],
      "source": [
        "#define hyperparameter grids for each model\n",
        "param_grids = {\n",
        "    'K-Nearest Neighbors': {'n_neighbors': [3, 5, 7]},\n",
        "    'Logistic Regression': {'C': [0.1, 1, 10]},\n",
        "    'Support Vector Machine': {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 50, 100, 'scale', 'auto']}\n",
        "}\n",
        "\n",
        "#instantiate classification models with default parameters\n",
        "models = {\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Support Vector Machine': SVC()\n",
        "}\n",
        "\n",
        "#fit models using GridSearchCV for hyperparameter tuning\n",
        "for name, model in models.items():\n",
        "    grid_search = GridSearchCV(model, param_grids[name], cv = 5, scoring = 'f1')\n",
        "    grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test_normalized)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    best_estimators1 = {}\n",
        "    best_estimators1[name] = grid_search.best_estimator_\n",
        "    best_estimators2.update(best_estimators1)\n",
        "    print(f'{name} Classification Report:\\n{report}\\nBest Parameters: {grid_search.best_params_}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7uqAirEdu2G"
      },
      "outputs": [],
      "source": [
        "#define hyperparameter grids for each model\n",
        "param_grids = {\n",
        "    'Decision Tree': {'max_depth': [3, 5, 7, 12, None]},\n",
        "    'Random Forest': {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7, 12, None]},\n",
        "    'XGBoost': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1], 'max_depth': [3, 5, 7]},\n",
        "    'GradientBoostingClassifier': {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1, 0.5]},\n",
        "    'CatBoost': {'iterations': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1]}\n",
        "}\n",
        "\n",
        "#instantiate classification models with default parameters\n",
        "models = {\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'XGBoost': XGBClassifier(),\n",
        "    'GradientBoostingClassifier': GradientBoostingClassifier(random_state=4646),\n",
        "    'CatBoost': CatBoostClassifier(verbose=0)\n",
        "}\n",
        "\n",
        "#fit models using GridSearchCV for hyperparameter tuning\n",
        "for name, model in models.items():\n",
        "    grid_search = GridSearchCV(model, param_grids[name], cv = 5, scoring = 'f1')\n",
        "    grid_search.fit(X_train_resampled2, y_train_resampled2)\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    best_estimators1 = {}\n",
        "    best_estimators1[name] = grid_search.best_estimator_\n",
        "    best_estimators2.update(best_estimators1)\n",
        "    print(f'{name} Classification Report:\\n{report}\\nBest Parameters: {grid_search.best_params_}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BleBzaYd5w4"
      },
      "source": [
        "## Ensemble Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtiUL7PaeEWF"
      },
      "outputs": [],
      "source": [
        "estimators = [\n",
        "    ('CatBoost', catBoost_pipeline),\n",
        "    ('XGBoost', xgboost_pipeline),\n",
        "    ('GradientBoostingClassifier', gradientBoosting_pipeline),\n",
        "    ('Support Vector Machine', svm_pipeline)\n",
        "]\n",
        "\n",
        "# Define the final estimator (meta-model)\n",
        "final_estimator = GradientBoostingClassifier(random_state=4646)\n",
        "\n",
        "# Create the stacking classifier\n",
        "stacking_model = StackingClassifier(estimators=estimators, final_estimator=final_estimator, cv=5)\n",
        "\n",
        "# Fit the stacking classifier on the training data\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = stacking_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(f'Stacking Classifier Classification Report:\\n{report}\\n')\n",
        "\n",
        "# Evaluate stacking model\n",
        "y_pred_stacking = stacking_model.predict(X_test)\n",
        "if hasattr(stacking_model, \"predict_proba\"):\n",
        "    y_pred_proba_stacking = stacking_model.predict_proba(X_test)[:, 1]\n",
        "else:\n",
        "    y_pred_proba_stacking = None\n",
        "\n",
        "stack_roc_auc_score = roc_auc_score(y_test, y_pred_proba_stacking) if y_pred_proba_stacking is not None else 'N/A'\n",
        "print(f'Stacking Classifier ROC AUC Score: {stack_roc_auc_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkCt6AA3wYbo"
      },
      "outputs": [],
      "source": [
        "estimators = [\n",
        "    ('CatBoost', catBoost_pipeline),\n",
        "    ('XGBoost', xgboost_pipeline)\n",
        "]\n",
        "\n",
        "# Define the final estimator (meta-model)\n",
        "final_estimator = LogisticRegression()\n",
        "\n",
        "# Create the stacking classifier\n",
        "stacking_model = StackingClassifier(estimators=estimators, final_estimator=final_estimator, cv=5)\n",
        "\n",
        "# Fit the stacking classifier on the training data\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = stacking_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(f'Stacking Classifier Classification Report:\\n{report}\\n')\n",
        "\n",
        "# Evaluate stacking model\n",
        "y_pred_stacking = stacking_model.predict(X_test)\n",
        "if hasattr(stacking_model, \"predict_proba\"):\n",
        "    y_pred_proba_stacking = stacking_model.predict_proba(X_test)[:, 1]\n",
        "else:\n",
        "    y_pred_proba_stacking = None\n",
        "\n",
        "stack_roc_auc_score = roc_auc_score(y_test, y_pred_proba_stacking) if y_pred_proba_stacking is not None else 'N/A'\n",
        "print(f'Stacking Classifier ROC AUC Score: {stack_roc_auc_score}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK65eZ2i4GW9"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5qNDSQc2WL2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=stacking_model.classes_, yticklabels=stacking_model.classes_)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMHfs_qa4KFF"
      },
      "source": [
        "### K-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xcs9Fbvf07TG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\n",
        "\n",
        "k = 5  # Number of folds\n",
        "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=4646)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "scores = cross_val_score(stacking_model, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "print(f\"Accuracy Scores for each fold: {scores}\")\n",
        "print(f\"Mean Accuracy: {scores.mean():.2f}\")\n",
        "print(f\"Standard Deviation: {scores.std():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6i2Wenj4ykk"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "roc_auc = {}\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_stacking, pos_label=1)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=1, label='Random guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFzi8Alk4SJU"
      },
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbgbLH_OwvZ2"
      },
      "outputs": [],
      "source": [
        "# Define the path to save the model\n",
        "model_path = '/content/Stack_model2.joblib'\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(stacking_model, model_path)\n",
        "\n",
        "print(f\"Model saved successfully at: {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX-CAIuu8wDz"
      },
      "outputs": [],
      "source": [
        "X_train_resampled.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSTRu5ZP8rh8"
      },
      "source": [
        "# ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWElDzqADHKq"
      },
      "outputs": [],
      "source": [
        "#split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 4646, shuffle = True, stratify = y)\n",
        "\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size = 0.3, random_state = 4646, shuffle = True, stratify = y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4B9CGMezE7rh"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train_normalized = X_train.copy()\n",
        "X_train_normalized = scaler.fit_transform(X_train[columns_to_scale])\n",
        "\n",
        "X_test_normalized = X_test.copy()\n",
        "X_test_normalized = scaler.transform(X_test[columns_to_scale])\n",
        "\n",
        "X_valid_normalized = X_valid.copy()\n",
        "X_valid_normalized = scaler.transform(X_valid[columns_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba2fIK0oFraR"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(sampling_strategy='minority')\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_normalized, y_train)\n",
        "y_train_resampled.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w214O_eyBLLT"
      },
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "  ax1.plot(history.history['loss'], label='loss')\n",
        "  ax1.plot(history.history['val_loss'], label='val_loss')\n",
        "  ax1.set_xlabel('Epoch')\n",
        "  ax1.set_ylabel('Binary crossentropy')\n",
        "  ax1.grid(True)\n",
        "\n",
        "  ax2.plot(history.history['accuracy'], label='accuracy')\n",
        "  ax2.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "  ax2.set_xlabel('Epoch')\n",
        "  ax2.set_ylabel('Accuracy')\n",
        "  ax2.grid(True)\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsbVQg0dx8af"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, y_train, num_nodes, dropout_prob, lr, batch_size, epochs):\n",
        "  nn_model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(num_nodes, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "      tf.keras.layers.Dropout(dropout_prob),\n",
        "      tf.keras.layers.Dense(num_nodes, activation='relu'),\n",
        "      tf.keras.layers.Dropout(dropout_prob),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  nn_model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  history = nn_model.fit(\n",
        "    X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_valid_normalized, y_valid), verbose=0\n",
        "  )\n",
        "\n",
        "  return nn_model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1qW0nDlBRHK"
      },
      "outputs": [],
      "source": [
        "least_val_loss = float('inf')\n",
        "least_loss_model = None\n",
        "epochs=100\n",
        "for num_nodes in [52, 78, 32]:\n",
        "  for dropout_prob in[0, 0.2]:\n",
        "    for lr in [0.01, 0.005, 0.001]:\n",
        "      for batch_size in [32, 64, 128]:\n",
        "        print(f\"{num_nodes} nodes, dropout {dropout_prob}, lr {lr}, batch size {batch_size}\")\n",
        "        model, history = train_model(X_train_resampled, y_train_resampled, num_nodes, dropout_prob, lr, batch_size, epochs)\n",
        "        plot_history(history)\n",
        "        val_loss = model.evaluate(X_valid_normalized, y_valid)[0]\n",
        "        if val_loss < least_val_loss:\n",
        "          least_val_loss = val_loss\n",
        "          least_loss_model = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uI11WnJeBR6K"
      },
      "outputs": [],
      "source": [
        "y_pred = least_loss_model.predict(X_test_normalized)\n",
        "y_pred = (y_pred > 0.5).astype(int).reshape(-1,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGIZUFmBBUzp"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR0G4Q-0LY9a"
      },
      "source": [
        "# Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL7OdZUBLYDi"
      },
      "outputs": [],
      "source": [
        "!pip install flask-ngrok flask-cors pyngrok shap pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3p4Q_i5pTVdw"
      },
      "outputs": [],
      "source": [
        "!pip install flask-ngrok flask shap pandas scikit-learn joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eowcbnmILbyr"
      },
      "outputs": [],
      "source": [
        "#%%writefile app.py\n",
        "import pandas as pd\n",
        "import shap\n",
        "import numpy as np\n",
        "from flask import Flask, request, render_template_string, redirect, url_for\n",
        "from pyngrok import ngrok\n",
        "import joblib\n",
        "import threading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiySsYaar1dS"
      },
      "outputs": [],
      "source": [
        "model_path = '/content/Stack_std_LR_model3.joblib'\n",
        "try:\n",
        "    loaded_model = joblib.load(model_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Model file not found at {model_path}\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "FEATURE_NAMES = [\n",
        "    'Age', 'BMI', 'Smoking', 'AlcoholConsumption', 'PhysicalActivity', 'DietQuality',\n",
        "    'SleepQuality', 'FamilyHistoryAlzheimers', 'CardiovascularDisease', 'Diabetes',\n",
        "    'Depression', 'HeadInjury', 'Hypertension', 'SystolicBP', 'DiastolicBP',\n",
        "    'CholesterolTotal', 'CholesterolLDL', 'CholesterolHDL', 'CholesterolTriglycerides',\n",
        "    'MMSE', 'FunctionalAssessment', 'MemoryComplaints', 'BehavioralProblems', 'ADL',\n",
        "    'Confusion', 'Disorientation', 'PersonalityChanges', 'DifficultyCompletingTasks',\n",
        "    'Forgetfulness', 'Gender_Female', 'Gender_Male', 'Ethnicity_African American',\n",
        "    'Ethnicity_Asian', 'Ethnicity_Caucasian', 'Ethnicity_Other',\n",
        "    \"EducationLevel_Bachelor's\", 'EducationLevel_High School',\n",
        "    'EducationLevel_Higher', 'EducationLevel_None'\n",
        "]\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    \"\"\"Redirects the base URL to the prediction form.\"\"\"\n",
        "    return redirect(url_for('predict_form'))\n",
        "\n",
        "@app.route('/predict', methods=['GET', 'POST'])\n",
        "def predict_form():\n",
        "    \"\"\"\n",
        "    Handles both displaying the form (GET) and processing the prediction (POST).\n",
        "    \"\"\"\n",
        "    if request.method == 'POST':\n",
        "        try:\n",
        "            features = [float(request.form[name]) for name in FEATURE_NAMES]\n",
        "\n",
        "            prediction = loaded_model.predict([features])\n",
        "            prediction_proba = loaded_model.predict_proba([features])[0][1]\n",
        "\n",
        "            if prediction[0] == 1:\n",
        "                result = f\"Alzheimer ALERT!! (Risk Score: {prediction_proba:.2f})\"\n",
        "                result_color = '#dc3545'\n",
        "            else:\n",
        "                result = f\"No significant risk of Alzheimer's detected. (Risk Score: {prediction_proba:.2f})\"\n",
        "                result_color = '#28a745'\n",
        "\n",
        "            return f'''\n",
        "                <!DOCTYPE html>\n",
        "                <html>\n",
        "                <head><title>Prediction Result</title></head>\n",
        "                <body style=\"font-family: 'Segoe UI', sans-serif; background-color: #f0f2f5; display: flex; align-items: center; justify-content: center; height: 100vh; margin: 0;\">\n",
        "                    <div style=\"max-width: 600px; margin: 40px auto; padding: 30px; background: #fff; border-radius: 10px; box-shadow: 0 4px 20px rgba(0,0,0,0.1); text-align: center;\">\n",
        "                        <h2 style=\"color: {result_color}; font-size: 1.8rem;\">Prediction Result</h2>\n",
        "                        <p style=\"font-size: 1.2rem; margin: 20px 0;\">{result}</p>\n",
        "                        <a href=\"/predict\" style=\"display: inline-block; padding: 12px 25px; background: #007bff; color: white; text-decoration: none; border-radius: 5px; transition: background 0.3s;\">Make another prediction</a>\n",
        "                    </div>\n",
        "                </body>\n",
        "                </html>\n",
        "            '''\n",
        "\n",
        "        except Exception as e:\n",
        "            error_message = f\"Error processing your request: {e}. Please ensure all fields are filled with valid numbers.\"\n",
        "            return f'''\n",
        "                 <!DOCTYPE html>\n",
        "                <html>\n",
        "                <head><title>Error</title></head>\n",
        "                <body style=\"font-family: 'Segoe UI', sans-serif; background-color: #f0f2f5; display: flex; align-items: center; justify-content: center; height: 100vh; margin: 0;\">\n",
        "                    <div style=\"max-width: 600px; margin: 40px auto; padding: 30px; background: #fff; border-radius: 10px; box-shadow: 0 4px 20px rgba(0,0,0,0.1); text-align: center;\">\n",
        "                        <h2 style=\"color: #dc3545; font-size: 1.8rem;\">An Error Occurred</h2>\n",
        "                        <p style=\"font-size: 1.2rem; margin: 20px 0; color: #555;\">{error_message}</p>\n",
        "                        <a href=\"/predict\" style=\"display: inline-block; padding: 12px 25px; background: #007bff; color: white; text-decoration: none; border-radius: 5px; transition: background 0.3s;\">Go back to the form</a>\n",
        "                    </div>\n",
        "                </body>\n",
        "                </html>\n",
        "            '''\n",
        "\n",
        "    styles = \"\"\"\n",
        "    <style>\n",
        "        * { box-sizing: border-box; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; }\n",
        "        body { background-color: #f0f2f5; margin: 0; padding: 20px; color: #333; }\n",
        "        .container { max-width: 1200px; margin: 0 auto; background: white; border-radius: 10px; box-shadow: 0 0 20px rgba(0,0,0,0.1); overflow: hidden; }\n",
        "        header { background: linear-gradient(135deg, #1a6ea0, #3498db); color: white; padding: 30px 20px; text-align: center; }\n",
        "        header h1 { margin: 0; font-size: 2.2rem; }\n",
        "        header p { opacity: 0.9; max-width: 700px; margin: 10px auto 0; }\n",
        "        .form-container { padding: 30px; }\n",
        "        .form-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px 40px;}\n",
        "        .form-section { margin-bottom: 25px; }\n",
        "        .form-section h3 { margin-top: 0; padding-bottom: 10px; border-bottom: 2px solid #3498db; color: #2c3e50; }\n",
        "        .form-group { margin-bottom: 20px; }\n",
        "        label { display: block; margin-bottom: 8px; font-weight: 500; color: #2c3e50; }\n",
        "        input[type=\"text\"] { width: 100%; padding: 12px 15px; border: 1px solid #ddd; border-radius: 5px; font-size: 1rem; transition: all 0.3s; }\n",
        "        input[type=\"text\"]:focus { border-color: #3498db; outline: none; box-shadow: 0 0 0 3px rgba(52, 152, 219, 0.2); }\n",
        "        .hint { font-size: 0.85rem; color: #6c757d; margin-top: 5px; }\n",
        "        .submit-container { text-align: center; margin-top: 30px; padding-top: 20px; border-top: 1px solid #eee; }\n",
        "        input[type=\"submit\"] { background: linear-gradient(135deg, #28a745, #218838); color: white; border: none; padding: 14px 35px; font-size: 1.1rem; border-radius: 5px; cursor: pointer; transition: all 0.3s; }\n",
        "        input[type=\"submit\"]:hover { transform: translateY(-2px); box-shadow: 0 5px 15px rgba(0,0,0,0.15); }\n",
        "        .footer-note { text-align: center; margin-top: 20px; color: #6c757d; font-size: 0.9rem; padding: 0 20px 20px 20px; }\n",
        "    </style>\n",
        "    \"\"\"\n",
        "\n",
        "    def form_field(name, label, hint):\n",
        "        return f'''\n",
        "        <div class=\"form-group\">\n",
        "            <label for=\"{name}\">{label}</label>\n",
        "            <input type=\"text\" id=\"{name}\" name=\"{name}\" required>\n",
        "            <div class=\"hint\">{hint}</div>\n",
        "        </div>\n",
        "        '''\n",
        "\n",
        "    form_html = f\"\"\"\n",
        "    <!DOCTYPE html>\n",
        "    <html>\n",
        "    <head>\n",
        "        <title>Alzheimer's Disease Prediction</title>\n",
        "        {styles}\n",
        "    </head>\n",
        "    <body>\n",
        "        <div class=\"container\">\n",
        "            <header>\n",
        "                <h1>Alzheimer's Disease Risk Assessment</h1>\n",
        "                <p>Fill in the health information below to assess your risk. This tool provides an estimate and is not a medical diagnosis.</p>\n",
        "            </header>\n",
        "\n",
        "            <div class=\"form-container\">\n",
        "                <form method=\"post\">\n",
        "                    <div class=\"form-grid\">\n",
        "\n",
        "                        <div class=\"form-section\">\n",
        "                            <h3>Personal & Demographic</h3>\n",
        "                            {form_field('Age', 'Age', 'In years (e.g., 75)')}\n",
        "                            {form_field('Gender_Male', 'Gender: Male', 'Enter 1 for Male, 0 for otherwise')}\n",
        "                            {form_field('Gender_Female', 'Gender: Female', 'Enter 1 for Female, 0 for otherwise')}\n",
        "                            {form_field(\"EducationLevel_Bachelor's\", \"Education: Bachelor's\", 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('EducationLevel_High School', 'Education: High School', 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('EducationLevel_Higher', 'Education: Higher Degree', 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('EducationLevel_None', 'Education: None', 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('Ethnicity_Caucasian', 'Ethnicity: Caucasian', 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('Ethnicity_African American', 'Ethnicity: African American', 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('Ethnicity_Asian', 'Ethnicity: Asian', 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('Ethnicity_Other', 'Ethnicity: Other', 'Enter 1 if yes, 0 if no')}\n",
        "                        </div>\n",
        "\n",
        "                        <div class=\"form-section\">\n",
        "                            <h3>Health Metrics</h3>\n",
        "                            {form_field('BMI', 'Body Mass Index (BMI)', 'e.g., 22.5')}\n",
        "                            {form_field('SystolicBP', 'Systolic Blood Pressure', 'Top number (e.g., 120 mmHg)')}\n",
        "                            {form_field('DiastolicBP', 'Diastolic Blood Pressure', 'Bottom number (e.g., 80 mmHg)')}\n",
        "                            {form_field('CholesterolTotal', 'Total Cholesterol', 'e.g., 180 mg/dL')}\n",
        "                            {form_field('CholesterolLDL', 'LDL Cholesterol (\"Bad\")', 'e.g., 110 mg/dL')}\n",
        "                            {form_field('CholesterolHDL', 'HDL Cholesterol (\"Good\")', 'e.g., 50 mg/dL')}\n",
        "                            {form_field('CholesterolTriglycerides', 'Triglycerides', 'e.g., 150 mg/dL')}\n",
        "                            {form_field('MMSE', 'MMSE Score', 'Mini-Mental State Examination (0-30)')}\n",
        "                            {form_field('ADL', 'Activities of Daily Living (ADL)', 'Score from 0-10')}\n",
        "                            {form_field('FunctionalAssessment', 'Functional Assessment', 'Score from 0-10')}\n",
        "                        </div>\n",
        "\n",
        "                        <div class=\"form-section\">\n",
        "                            <h3>Lifestyle & Medical History</h3>\n",
        "                            {form_field('Smoking', 'Currently Smoking', 'Enter 1 for yes, 0 for no')}\n",
        "                            {form_field('AlcoholConsumption', 'Alcohol Consumption', 'Scale from 0-20')}\n",
        "                            {form_field('PhysicalActivity', 'Physical Activity Level', 'Scale from 0-10')}\n",
        "                            {form_field('DietQuality', 'Diet Quality', 'Scale from 0-10')}\n",
        "                            {form_field('SleepQuality', 'Sleep Quality', 'Scale from 4-10')}\n",
        "                            {form_field('FamilyHistoryAlzheimers', \"Family History of Alzheimer's\", 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('CardiovascularDisease', 'History of Cardiovascular Disease', 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('Diabetes', 'History of Diabetes', 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('Hypertension', 'History of Hypertension', 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('Depression', 'History of Depression', 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('HeadInjury', 'History of Significant Head Injury', 'Enter 1 if yes, 0 if no')}\n",
        "                        </div>\n",
        "\n",
        "                        <div class=\"form-section\">\n",
        "                            <h3>Cognitive & Behavioral Symptoms</h3>\n",
        "                            {form_field('MemoryComplaints', 'Subjective Memory Complaints', 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('Forgetfulness', 'Observable Forgetfulness', 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('DifficultyCompletingTasks', 'Difficulty with Familiar Tasks', 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('Confusion', 'Episodes of Confusion', 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('Disorientation', 'Episodes of Disorientation', 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('PersonalityChanges', 'Observed Personality Changes', 'Enter 1 if yes, 0 if no')}\n",
        "                            {form_field('BehavioralProblems', 'Observed Behavioral Problems', 'Enter 1 if yes, 0 if no')}\n",
        "                        </div>\n",
        "\n",
        "                    </div>\n",
        "\n",
        "                    <div class=\"submit-container\">\n",
        "                        <input type=\"submit\" value=\"Assess Alzheimer's Risk\">\n",
        "                    </div>\n",
        "                </form>\n",
        "            </div>\n",
        "             <div class=\"footer-note\">\n",
        "                <p><strong>Disclaimer:</strong> This tool is for informational purposes only and does not constitute a medical diagnosis. Consult a healthcare professional for any health concerns.</p>\n",
        "            </div>\n",
        "        </div>\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "    return render_template_string(form_html)\n",
        "\n",
        "def start_flask():\n",
        "    \"\"\"Starts the Flask server.\"\"\"\n",
        "    app.run(port=5000)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    NGROK_AUTH_TOKEN = \"31HXHWmx4xOeNi5PI55IGhuFA7S_3JBeA9Ab7mH9JstPWFyiT\"\n",
        "\n",
        "    if not NGROK_AUTH_TOKEN:\n",
        "        print(\"Error: ngrok authtoken is missing. Please add it to the script.\")\n",
        "    else:\n",
        "        ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "        flask_thread = threading.Thread(target=start_flask, daemon=True)\n",
        "        flask_thread.start()\n",
        "\n",
        "        try:\n",
        "            # Start ngrok tunnel\n",
        "            public_url = ngrok.connect(5000)\n",
        "            print(\"=\"*50)\n",
        "            print(f\"✅ The Alzheimer's Prediction App is LIVE!\")\n",
        "            print(f\"   Public URL: {public_url.public_url}\")\n",
        "            print(\"=\"*50)\n",
        "            print(\"(Press CTRL+C to shut down the server)\")\n",
        "\n",
        "            flask_thread.join()\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n shutting down server and ngrok tunnel...\")\n",
        "            ngrok.kill()\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "            ngrok.kill()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}